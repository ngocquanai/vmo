[
  
  {
    "title": "Similar Properties of Similarity Matrix",
    "url": "/posts/similarity-matrix/",
    "categories": "Mathematics, Linear Algebra",
    "tags": "similar matrices, similarity matrix, mathematics, algebra",
    "date": "2023-08-20 20:00:00 +0700",
    





    
    "snippet": "Abstract:  Initially I will introduce specific definitions relevant to its topic. Subsequently, it will explore various properties common to similar matrices, such as trace, rank, determinant, amon...",
    "content": "Abstract:  Initially I will introduce specific definitions relevant to its topic. Subsequently, it will explore various properties common to similar matrices, such as trace, rank, determinant, among others. Finally, the paper will present criteria for determining whether any two given matrices are similar.DEFINITIONS1.1: SIMILARITY MATRIXTwo square \\(n \\times n\\) matrices A and B are called similar if there exists an invertible \\(n*n\\) matrix \\(P\\) such that\\[B = P^{-1}AP\\]1.2: REPRESENTATION OF A VECTOR\\(V\\) is a vector space with the basis \\(B=\\left&lt;\\overrightarrow{\\beta_1}, \\overrightarrow{\\beta_2}, \\ldots, \\overrightarrow{\\beta_n}\\right&gt; , \\vec{v} \\in V,  \\alpha_1, \\ldots, \\alpha_n \\in \\mathbb{R}\\) such that \\(\\vec{v}=\\alpha_1 \\overrightarrow{\\beta_1}+\\alpha_2 \\overrightarrow{\\beta_2}+\\ldots+\\alpha_n \\overrightarrow{\\beta_n}.\\) Then we have\\[{Rep}_B(\\vec{v})=\\left(\\begin{array}{c}\\overrightarrow{\\beta_1} \\\\ \\overrightarrow{\\beta_2} \\\\ \\vdots \\\\ \\overrightarrow{\\beta_n}\\end{array}\\right)\\]1.3: MATRIX REPRESENTATION\\(V, W\\) are vector spaces with dimension \\(n, m\\) and basis \\(B, D\\). \\(f \\colon V \\to W\\) is a linear mapping. If we have \\(\\operatorname{Rep}_D(h(\\overrightarrow{\\beta_1}))=\\left(\\begin{array}{c}h_{1,1} \\\\ h_{2,1} \\\\ \\vdots \\\\ h_{n, 1}\\end{array}\\right), \\ldots, \\operatorname{Rep}_D(h(\\overrightarrow{\\beta_n}))=\\left(\\begin{array}{c}h_{1, n} \\\\ h_{2, n} \\\\ \\vdots \\\\ h_{n, n}\\end{array}\\right)\\). Then\\[\\left(\\begin{array}{cccc}h_{1,1} &amp; h_{1,2} &amp; \\cdots &amp; h_{1, n} \\\\ h_{2,1} &amp; h_{2,2} &amp; \\cdots &amp; h_{2, n} \\\\ \\vdots &amp; \\vdots &amp;  &amp; \\vdots \\\\ h_{n, 1} &amp; h_{n, 2} &amp; \\cdots &amp; h_{n, n}\\end{array}\\right)\\]is called matrix representation of mapping f with respect to the bases \\(B, D\\), notated by \\({Rep}_{B,D}(f)\\)1.4: DETERMINANT OF MATRIX\\(n \\times n\\) determinant is a function \\(f \\colon M_{n \\times n} \\rightarrow \\mathbb{R}\\) such that (1) \\(\\operatorname{det}\\left(\\overrightarrow{p_1}, \\ldots, k \\overrightarrow{p_i}+\\overrightarrow{p_j}, \\ldots, \\overrightarrow{p_n}\\right)=\\operatorname{det}\\left(\\overrightarrow{p_1}, \\ldots, \\overrightarrow{p_j}, \\ldots, \\overrightarrow{p_n}\\right)\\), for all \\(k \\in \\mathbb{R}\\) (2) \\(\\operatorname{det}\\left(\\overrightarrow{p_1}, \\ldots, \\overrightarrow{p_j}, \\ldots, \\overrightarrow{p_i}, \\ldots, \\overrightarrow{p_n}\\right)=-\\operatorname{det}\\left(\\overrightarrow{p_1}, \\ldots, \\overrightarrow{p_i}, \\ldots, \\overrightarrow{p_j}, \\ldots, \\overrightarrow{p_n}\\right)\\) (3) \\(\\operatorname{det}\\left(\\overrightarrow{p_1}, \\ldots, k \\overrightarrow{p_i}, \\ldots, \\overrightarrow{p_n}\\right) = k \\operatorname{det}\\left(\\overrightarrow{p_1}, \\ldots, \\overrightarrow{p_i}, \\ldots, \\overrightarrow{p_n}\\right)\\), for all \\(k \\in \\mathbb{R}\\) (4) \\(\\operatorname{det}(I) = 1\\), \\(I\\) is the identity matrix. Normally, we use the notation \\(|T|\\) instead of \\(\\operatorname{det}(T)\\).1.5: TRACE OF MATRIXThe trace of a square matrix \\(A\\) is the sum of elements on the main diagonal of matrix \\(A\\), denoted by \\(tr(A)\\)1.6: POLYNOMIAL OF MATRIX\\(T\\) is a square matrix, \\(f(x)\\) is a polynomial with degree n \\(f(x) = c_n x^n + c_{n-1} x^{n-1} + \\cdots + c_1 x + c_0\\) \\((c_i \\in \\mathbb{R})\\). Then we have \\(f(T) = c_n T^n + c_{n-1} T^{n-1} + \\cdots + c_1 T + c_0 I\\) (\\(I\\) is identity matrix) is a polynomial of matrix \\(T\\) and also a square matrix of the same size as \\(T\\).1.7: MINIMAL POLYNOMIALFor a square matrix \\(T\\), its minimal polynomial is the monic polynomial \\(f\\) of the lowest degree such that \\(f(T) = 0\\).1.8: INDEX OF NIPOTENTA square matrix $A$ is said to have a nilpotent index $k$ if \\(k\\) is the smallest natural number(if exists) such that $A^k = 0$.1.9: SUBDIAGONALThe subdiagonal of a square matrix is the line immediately below the main diagonal of the matrix.1.10: JORDAN BLOCKA Jordan block is a square matrix where the off-diagonal entries are zero, the entries on the main diagonal are all $\\lambda$ (where $\\lambda \\in \\mathbb{C}$), and every entry on the subdiagonal is 1.1.11: JORDAN CANONICAL FORMThe square matrix $A$ can be represented in the form of a Jordan normal form if \\[A = \\left(\\begin{array}{cccc}J_{\\lambda_1} &amp; 0 &amp; \\cdots &amp; 0 \\\\0 &amp; J_{\\lambda_2} &amp; \\ddots &amp; \\vdots \\\\\\vdots &amp; \\ddots &amp; \\ddots &amp; 0 \\\\0 &amp; \\cdots &amp; 0 &amp; J_{\\lambda_k} \\\\\\end{array}\\right)\\]with \\(J_{\\lambda_i}\\) are Jordan blocks.1.12: CHARACTERISTIC POLYNOMIALA is an \\(n \\times n\\) matrix, the characteristic polynomial of A, denoted by \\(p_{A}(x)\\) is defined by\\[p_{A}(x) = \\operatorname{det}(A - xI)\\]where \\(I\\) denotes the \\(n \\times n\\) identity matrix.1.13: GEOMETRIC AND ALGEBRAIC MULTIPLICITYA is a square matrix with characteristic polynomial \\(f(x) = (x- \\lambda_1)^{m_1} (x - \\lambda_2)^{m_2} \\ldots (x- \\lambda_r)^{m_r}\\). Then \\(m_i\\) is called algebraic multiplicity corresponding to eigenvalue \\(\\lambda_i\\), the dimension of eigenspace corresponding to eigenvalue \\(\\lambda_i\\) is called geometric multiplicity.1.14: COFACTOR OF MATRIXConsider the \\(n \\times n\\) square matrix \\(T\\), we define the \\(i,j \\: minor\\) \\(M_{i,j}\\) of matrix \\(T\\) is the \\((n-1) \\times (n-1)\\) matrix obtained by eliminating the i-th row and j-th column in the matrix \\(T\\).Then we have i,j cofactor \\(T_{i,j} = (-1)^{i+j} \\operatorname{det}(M_{i,j})\\)1.15: MATRIX ADJOINTMatrix adjoint of square matrix T is denoted by\\[\\[\\text{adj}(T) = \\left(\\begin{array}{cccc}T_{1,1} &amp; T_{1,2} &amp; \\cdots &amp; T_{1,n} \\\\T_{2,1} &amp; T_{2,2} &amp; \\cdots &amp; T_{2,n} \\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\T_{n,1} &amp; T_{n,2} &amp; \\cdots &amp; T_{n,n}\\end{array}\\right)\\]\\]"
  },
  
  {
    "title": "Hello World, I'm NgocQuan",
    "url": "/posts/NgocQuan/",
    "categories": "blog post",
    "tags": "ngocquan",
    "date": "2023-01-31 23:24:25 +0700",
    





    
    "snippet": "This is my page where I will talk about my research about Natural Language Processing and some other interesting mathematics like Linear Algebra, Probability and Statistics, …\\[e^{i\\pi} = -1\\]“Lore...",
    "content": "This is my page where I will talk about my research about Natural Language Processing and some other interesting mathematics like Linear Algebra, Probability and Statistics, …\\[e^{i\\pi} = -1\\]“Lorem ipsum dolor sit amet, \\(e^{i\\pi} = -1\\) consectetur adipiscing elit.”  \\(e^{i\\pi} = -1\\)  \\(e^{i\\pi} = -1\\)  \\(e^{i\\pi} = -1\\) Image Caption Image Caption hereIn a quaint village, nestled among verdant hills, there lived x= 3 here.for i in range(n) :    print(i)    print(\"Hello World\")"
  }
  
]

